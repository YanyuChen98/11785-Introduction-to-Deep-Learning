{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNRZx788mX9H"
      },
      "source": [
        "# 0 Import Packages"
      ],
      "id": "NNRZx788mX9H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIby3J0IWvkY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "#!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "id": "MIby3J0IWvkY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm3kWq2Mmgoy"
      },
      "source": [
        "# 1 Connect to Drive"
      ],
      "id": "pm3kWq2Mmgoy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NatlNc00mfoD",
        "outputId": "937c0d97-c11d-4a60-99c5-ddb51483017b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "NatlNc00mfoD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtAM411hmj4N"
      },
      "source": [
        "# 2 Connect to Kaggle and Download Data"
      ],
      "id": "GtAM411hmj4N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3Nk8Wl2Q13G"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":\"yanyuc\",\"key\":\"dc3249c0209ecf021c2a7c30ff21d247\"} # This is personal user name and token\n",
        "!pwd\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "  json.dump(token, file)\n",
        "for i in range(2):\n",
        "  !chmod 600 /root/.kaggle/kaggle.json\n",
        "  !cp /root/.kaggle/kaggle.json -/.kaggle/\n",
        "  !kaggle config set -n path -v /root\n",
        "  !cat /root/.kaggle/kaggle.json\n"
      ],
      "id": "g3Nk8Wl2Q13G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX04QSZVmgPe"
      },
      "outputs": [],
      "source": [
        "!kaggle competitions download --force -c 11-785-s22-hw1p2\n",
        "!unzip /root/competitions/11-785-s22-hw1p2/11-785-s22-hw1p2.zip"
      ],
      "id": "xX04QSZVmgPe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXmip2Wpmr92"
      },
      "source": [
        "# 3 Define Components"
      ],
      "id": "OXmip2Wpmr92"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1cWB7uBmvr7"
      },
      "source": [
        "## Network"
      ],
      "id": "F1cWB7uBmvr7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcny8yCsWxmq"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm1d\n",
        "from torch.nn.modules.dropout import Dropout\n",
        "from torch.nn.modules.activation import ReLU\n",
        "from torch.nn.modules.activation import Mish\n",
        "\n",
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, context):\n",
        "        super(Network, self).__init__()\n",
        "        # TODO: Please try different architectures\n",
        "        in_size = (2 * context + 1) * 13\n",
        "        layers = [\n",
        "            nn.Linear(in_size, 4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.BatchNorm1d(4096),\n",
        "            nn.Mish(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(4096,40)\n",
        "        ]\n",
        "\n",
        "        for i in range(0, len(layers), 4):\n",
        "          nn.init.kaiming_normal_(layers[i].weight, mode='fan_in') \n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, A0):\n",
        "        x = self.layers(A0)\n",
        "        return x"
      ],
      "id": "Qcny8yCsWxmq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CowPNvxm0ED"
      },
      "source": [
        "## LibriSample and LibriItems"
      ],
      "id": "1CowPNvxm0ED"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr9VJwbGWxrY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, sample=28539, shuffle=True, partition=\"dev-clean\", csvpath=None, train=True): # The original sample in the starter notebook was 20000\n",
        "        # sample represent how many npy files will be preloaded for one __getitem__ call\n",
        "        self.sample = sample \n",
        "        \n",
        "        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n",
        "        self.Y_dir = data_path + \"/\" + partition +\"/transcript/\"\n",
        "        \n",
        "        self.X_names = os.listdir(self.X_dir)\n",
        "        self.Y_names = os.listdir(self.Y_dir)\n",
        "\n",
        "        # using a small part of the dataset to debug\n",
        "        if csvpath:\n",
        "          if train:\n",
        "            subset = self.parse_csv(csvpath)\n",
        "            self.X_names = [i for i in self.X_names if i in subset]\n",
        "            self.Y_names = [i for i in self.Y_names if i in subset]\n",
        "          else:\n",
        "            self.X_names = list(pd.read_csv(csvpath).file)\n",
        "\n",
        "        \n",
        "        if shuffle == True:\n",
        "            XY_names = list(zip(self.X_names, self.Y_names))\n",
        "            random.shuffle(XY_names)\n",
        "            self.X_names, self.Y_names = zip(*XY_names)\n",
        "        \n",
        "        assert(len(self.X_names) == len(self.Y_names))\n",
        "        self.length = len(self.X_names)\n",
        "        \n",
        "        self.PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n",
        "      \n",
        "    @staticmethod\n",
        "    def parse_csv(filepath):\n",
        "        subset = []\n",
        "        with open(filepath) as f:\n",
        "            f_csv = csv.reader(f)\n",
        "            for row in f_csv:\n",
        "                subset.append(row[1])\n",
        "        return subset[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.length / self.sample))\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n",
        "        \n",
        "        X, Y = [], []\n",
        "        for j in sample_range:\n",
        "            X_path = self.X_dir + self.X_names[j]\n",
        "            Y_path = self.Y_dir + self.Y_names[j]\n",
        "            \n",
        "            label = [self.PHONEMES.index(yy) for yy in np.load(Y_path)][1:-1]\n",
        "\n",
        "            X_data = np.load(X_path)\n",
        "            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n",
        "            X.append(X_data)\n",
        "            Y.append(np.array(label))\n",
        "            \n",
        "        X, Y = np.concatenate(X), np.concatenate(Y)\n",
        "        return X, Y\n",
        "    \n",
        "class LibriItems(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, Y, context = 0):\n",
        "        assert(X.shape[0] == Y.shape[0])\n",
        "        \n",
        "        self.length  = X.shape[0]\n",
        "        self.context = context\n",
        "\n",
        "        if context == 0:\n",
        "            self.X, self.Y = X, Y\n",
        "        else:\n",
        "            X = np.pad(X, ((context,context), (0,0)), 'constant', constant_values=(0,0))\n",
        "            self.X, self.Y = X, Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        if self.context == 0:\n",
        "            xx = self.X[i].flatten()\n",
        "            yy = self.Y[i]\n",
        "        else:\n",
        "            xx = self.X[i:(i + 2*self.context + 1)].flatten()\n",
        "            yy = self.Y[i]\n",
        "        return xx, yy\n",
        "    \n",
        "\n"
      ],
      "id": "Jr9VJwbGWxrY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0XesbV6m9Lw"
      },
      "source": [
        "## Train and Test"
      ],
      "id": "S0XesbV6m9Lw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cbb1d57"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train(args, model, device, train_samples, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    for i in range(len(train_samples)):\n",
        "        X, Y = train_samples[i]\n",
        "        train_items = LibriItems(X, Y, context=args['context'])\n",
        "        train_loader = torch.utils.data.DataLoader(train_items, batch_size=args['batch_size'], shuffle=True)\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.float().to(device)\n",
        "            target = target.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if batch_idx % args['log_interval'] == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(args, model, device, dev_samples):\n",
        "    model.eval()\n",
        "    true_y_list = []\n",
        "    pred_y_list = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(dev_samples)):\n",
        "            X, Y = dev_samples[i]\n",
        "\n",
        "            test_items = LibriItems(X, Y, context=args['context'])\n",
        "            test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "            for data, true_y in test_loader:\n",
        "                data = data.float().to(device)\n",
        "                true_y = true_y.long().to(device)                \n",
        "                \n",
        "                output = model(data)\n",
        "                pred_y = torch.argmax(output, axis=1)\n",
        "\n",
        "                pred_y_list.extend(pred_y.tolist())\n",
        "                true_y_list.extend(true_y.tolist())\n",
        "\n",
        "    train_accuracy =  accuracy_score(true_y_list, pred_y_list)\n",
        "    return train_accuracy\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    model = Network(args['context']).to(device)\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_model_hw1p2_6')) # Read the saved model\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # If you want to use full Dataset, please pass None to csvpath\n",
        "    train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=None)\n",
        "    dev_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"dev-clean\")\n",
        "\n",
        "    for epoch in range(1, args['epoch'] + 1):\n",
        "        train(args, model, device, train_samples, optimizer, criterion, epoch)\n",
        "        test_acc = test(args, model, device, dev_samples)\n",
        "        print('Dev accuracy ', test_acc)\n",
        "        \n",
        "        # Compare to decide if to save the model\n",
        "        if test_acc > 0.865: # The best accuracy is hard coded here because there were only few changes\n",
        "          # save the model to specified directory\n",
        "          torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw1p2_6') \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = {\n",
        "        'batch_size': 4096,\n",
        "        'context': 30,\n",
        "        'log_interval': 200,\n",
        "        'LIBRI_PATH': '/content/hw1p2_student_data',\n",
        "        'lr': 0.0009,\n",
        "        'epoch': 25\n",
        "    }\n",
        "    main(args)"
      ],
      "id": "2cbb1d57"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rZOI0A8nOT3"
      },
      "source": [
        "# 4 Submission Validation"
      ],
      "id": "_rZOI0A8nOT3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kew2YW5nDLD"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "        'batch_size': 4096,\n",
        "        'context': 30,\n",
        "        'log_interval': 200,\n",
        "        'LIBRI_PATH': '/content/hw1p2_student_data',\n",
        "        'lr': 0.0009,\n",
        "        'epoch': 25\n",
        "    }\n",
        "context = args['context']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Network(args['context'])\n",
        "# Load the best model. If you want to use the model just trained, make next line a comment\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_model_hw1p2_6')) \n",
        "model.to(device)"
      ],
      "id": "0Kew2YW5nDLD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgcKvSlTph1u"
      },
      "source": [
        "## Load the test data"
      ],
      "id": "GgcKvSlTph1u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoTRq1IMpnIp"
      },
      "outputs": [],
      "source": [
        "# Referenced from LibriItems class\n",
        "class ValidationItems(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, context = 0):\n",
        "        \n",
        "        self.length  = X.shape[0]\n",
        "        self.context = context\n",
        "\n",
        "        if context == 0:\n",
        "            self.X = X\n",
        "        else:\n",
        "            self.X = np.pad(X, ((self.context,self.context), (0,0)), 'constant', constant_values=(0, 0)) \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        if self.context == 0:\n",
        "            xx = self.X[i].flatten()\n",
        "        else:\n",
        "            xx = self.X[i:(i + 2 * self.context + 1)].flatten()\n",
        "        return xx\n",
        "\n"
      ],
      "id": "MoTRq1IMpnIp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlTI8P03pscp"
      },
      "outputs": [],
      "source": [
        "# Referenced from LibriSample class and Test() method\n",
        "def validate(args, model, device, lib_path):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.eval()\n",
        "  X_list = []\n",
        "  Y_list = []\n",
        "\n",
        "  X_names = os.listdir(lib_path)\n",
        "  X_names.sort()\n",
        "\n",
        "  for i in range(len(X_names)):\n",
        "    X_path = lib_path + X_names[i]\n",
        "    X_data = np.load(X_path)\n",
        "    X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n",
        "    X_list.append(X_data)\n",
        "  \n",
        "  X_list = np.concatenate(X_list)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "      validation_items = ValidationItems(X_list, context=args['context'])\n",
        "      validation_loader = torch.utils.data.DataLoader(validation_items, batch_size = args['batch_size'], shuffle=False)\n",
        "      \n",
        "      for data in validation_loader:\n",
        "        data = data.float().to(device)\n",
        "        output = model(data)\n",
        "        Y = torch.argmax(output, axis = 1)\n",
        "        Y_list += Y.tolist()\n",
        "      \n",
        "\n",
        "  return Y_list\n"
      ],
      "id": "NlTI8P03pscp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKdAA75Jpxhx"
      },
      "outputs": [],
      "source": [
        "lib_path = \"/content/hw1p2_student_data/test-clean/mfcc/\" # Argument for prediction\n",
        "prediction = validate(args, model, device, lib_path) # Predict the Test data\n"
      ],
      "id": "TKdAA75Jpxhx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submit to kaggle"
      ],
      "metadata": {
        "id": "sQSFi56WFzJI"
      },
      "id": "sQSFi56WFzJI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrVlpKW1pz9y"
      },
      "outputs": [],
      "source": [
        "submission_data = pd.DataFrame(data = {'Id': [i for i in range(len(prediction))], 'Label':prediction}, index=None) # Zip the prediction label and id into one dataframe\n",
        "submission_data.to_csv(\"submission.csv\",index=0) \n",
        "! kaggle competitions submit -c 11-785-s22-hw1p2 -f submission.csv -m \"yanyuc\""
      ],
      "id": "rrVlpKW1pz9y"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "hw1p2_s22_yanyuc.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "239d5711fd35d2bb9bad2d5ca41e22b79107b4494fe73df9033b517b748af271"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}