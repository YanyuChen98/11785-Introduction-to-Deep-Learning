{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jwLEd0gdPbSc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as ttf\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README\n",
        "\n",
        "I didn't try many architectures. I just used the ResNet34 structure from scratch according to the suggestion from the recitation. To build the ResNet34, I referenced some articles about how ResNet34 works and how to build it from scratch. \\\n",
        "\n",
        "This notebook is based on the starter notebook. \\\n",
        "\n",
        "To run the code, just run the following blocks in order. Notice that in the 'Let's train' part, I used some 'if-else' statements to save the model based on different accuracy it achieved. And I finally loaded the best model just after the 'Let's train' part. Then use it for validation and submission. \\\n",
        "\n",
        "I firstly used 'batch_size = 256\n",
        "lr = 0.1\n",
        "epochs = 150' as the starting parameter. Then after about 120 epchos, I changed these parameters into 'batch_size = 256\n",
        "lr = 0.01\n",
        "epochs = 70' and trained another 70 epochs to try to jump out of the local minimal to get a higher accuracy. \\\n",
        "\n",
        "Based on the suggestions from our mentor, I used data augmentation techniques in the 'Dataset & DataLoader' part. I mainly used flip, rotation and normalization. These techniques helped me achieve at least 3% higher accuracy. \\\n",
        "\n",
        "The final accuracy is about 85%.\n"
      ],
      "metadata": {
        "id": "Xgu2TFpN7eeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODOs\n",
        "As you go, please read the code and keep an eye out for TODOs!"
      ],
      "metadata": {
        "id": "1oxQNl-YVWHc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scOnMklwWBY6"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzL1oUOWAXuh",
        "outputId": "762f45e8-1aec-4abe-e6b4-dbee98648c8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6BksgPdkQwwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a367ae-c804-439a-d94a-938b2cd73fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 30 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 40 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 59 kB 5.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73275 sha256=a38544303483091da5d0efb05fedb90c454edd7e60fd4df752b78be7cc834600\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/f7/d8/c3902cacb7e62cb611b1ad343d7cc07f42f7eb76ae3a52f3d1\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"yanyuc\",\"key\":\"dc3249c0209ecf021c2a7c30ff21d247\"}') # Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3oFjaJTaRjT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50030805-58a7-4db2-aa92-a24f2f737b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s22-hw2p2-classification.zip to /content\n",
            "100% 2.35G/2.35G [00:25<00:00, 149MB/s]\n",
            "100% 2.35G/2.35G [00:25<00:00, 98.2MB/s]\n",
            "Downloading 11-785-s22-hw2p2-verification.zip to /content\n",
            " 95% 249M/263M [00:05<00:00, 42.4MB/s]\n",
            "100% 263M/263M [00:06<00:00, 45.9MB/s]\n",
            "11-785-s22-hw2p2-classification.zip   sample_data\n",
            "11-785-s22-hw2p2-verification.zip     train_subset\n",
            "classification\t\t\t      verification\n",
            "classification_sample_submission.csv  verification_sample_submission.csv\n",
            "drive\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c 11-785-s22-hw2p2-classification\n",
        "!kaggle competitions download -c 11-785-s22-hw2p2-verification\n",
        "\n",
        "!unzip -q 11-785-s22-hw2p2-classification.zip\n",
        "!unzip -q 11-785-s22-hw2p2-verification.zip\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBTLCyocZBGS"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "13usn4nYZCvJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The well-accepted SGD batch_size & lr combination for CNN classification is 256 batch size for 0.1 learning rate.\n",
        "When changing batch size for SGD, follow the linear scaling rule - halving batch size -> halve learning rate, etc.\n",
        "This is less theoretically supported for Adam, but in my experience, it's a decent ballpark estimate.\n",
        "\"\"\"\n",
        "batch_size = 256\n",
        "lr = 0.1\n",
        "epochs = 150 # Just for the early submission. We'd want you to train like 50 epochs for your main submissions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Block"
      ],
      "metadata": {
        "id": "_8JfsouvpUiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channel,out_channel, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.stride = stride\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.downsample = downsample\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "          shortcut = self.downsample(x)\n",
        "        \n",
        "        out += shortcut\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "vxkPVuoppanM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIqmojPaWD0H"
      },
      "source": [
        "# Very Simple Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ny-mh_ocWIJR"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import ReLU\n",
        "class Network(nn.Module):\n",
        "    \"\"\"\n",
        "    The Very Low early deadline architecture is a 4-layer CNN.\n",
        "    The first Conv layer has 64 channels, kernel size 7, and stride 4.\n",
        "    The next three have 128, 256, and 512 channels. Each have kernel size 3 and stride 2.\n",
        "    Think about what the padding should be for each layer to not change spatial resolution.\n",
        "    Each Conv layer is accompanied by a Batchnorm and ReLU layer.\n",
        "    Finally, you want to average pool over the spatial dimensions to reduce them to 1 x 1.\n",
        "    Then, remove (Flatten?) these trivial 1x1 dimensions away.\n",
        "    Look through https://pytorch.org/docs/stable/nn.html \n",
        "    TODO: Fill out the model definition below! \n",
        "\n",
        "    Why does a very simple network have 4 convolutions?\n",
        "    Input images are 224x224. Note that each of these convolutions downsample.\n",
        "    Downsampling 2x effectively doubles the receptive field, increasing the spatial\n",
        "    region each pixel extracts features from. Downsampling 32x is standard\n",
        "    for most image models.\n",
        "\n",
        "    Why does a very simple network have high channel sizes?\n",
        "    Every time you downsample 2x, you do 4x less computation (at same channel size).\n",
        "    To maintain the same level of computation, you 2x increase # of channels, which \n",
        "    increases computation by 4x. So, balances out to same computation.\n",
        "    Another intuition is - as you downsample, you lose spatial information. Want\n",
        "    to preserve some of it in the channel dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, block, num_classes=7000):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) # TODO: Conv group 1\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(3, 2, 1)\n",
        "\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            block(64, 64),\n",
        "            block(64, 64),\n",
        "            block(64, 64)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = self._make_layer(block, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, 6, stride=2)\n",
        "        #self.linear = nn.Linear(512, 512)\n",
        "        #self.dropout = nn.Dropout(0.2)\n",
        "        self.layer4 = self._make_layer(block, 512, 3, stride=2)\n",
        "\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.cls_layer = nn.Linear(512, num_classes)\n",
        "    \n",
        "    def _make_layer(self, block, outchannel, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != outchannel:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, outchannel, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel, outchannel, stride, downsample))\n",
        "        self.in_channel = outchannel\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.in_channel, outchannel))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    \n",
        "    def forward(self, x, return_feats=False):\n",
        "        \"\"\"\n",
        "        What is return_feats? It essentially returns the second-to-last-layer\n",
        "        features of a given image. It's a \"feature encoding\" of the input image,\n",
        "        and you can use it for the verification task. You would use the outputs\n",
        "        of the final classification layer for the classification task.\n",
        "\n",
        "        You might also find that the classification outputs are sometimes better\n",
        "        for verification too - try both.\n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        #x = self.linear(x)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)     # convert 1 X 1 to vector\n",
        "        x = self.cls_layer(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwYR-CLwX09u"
      },
      "source": [
        "# Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "awE5BxlqX2o7"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Transforms (data augmentation) is quite important for this task.\n",
        "Go explore https://pytorch.org/vision/stable/transforms.html for more details\n",
        "\"\"\"\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "DATA_DIR = \"/content\" \n",
        "TRAIN_DIR = osp.join(DATA_DIR, \"classification/classification/train\") # This is a smaller subset of the data. Should change this to classification/classification/train train_subset/train_subset\n",
        "VAL_DIR = osp.join(DATA_DIR, \"classification/classification/dev\")\n",
        "TEST_DIR = osp.join(DATA_DIR, \"classification/classification/test\")\n",
        "\n",
        "train_transforms = [ttf.RandomHorizontalFlip(p=0.5),\n",
        "                    ttf.RandomRotation((-40, 40)),\n",
        "                    ttf.ToTensor(),\n",
        "                    ttf.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])] # , ttf.Normalize([0, 0, 0], [1, 1, 1]) ttf.RandomHorizontalFlip(p=0.5), ttf.RandomCrop(32, padding=4),\n",
        "val_transforms = [ttf.ToTensor(), ttf.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])] # , ttf.Normalize([0, 0, 0], [1, 1, 1]) ttf.CenterCrop((64, 64)),\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR,\n",
        "                                                 transform=ttf.Compose(train_transforms))\n",
        "val_dataset = torchvision.datasets.ImageFolder(VAL_DIR,\n",
        "                                               transform=ttf.Compose(val_transforms))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True, num_workers=2, pin_memory=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        drop_last=True, num_workers=2, pin_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZCn0qHuZRKj"
      },
      "source": [
        "# Setup everything for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UowI9OcUYPjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a75902f-7aa8-4af5-d899-088377857435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Params: 24875672\n"
          ]
        }
      ],
      "source": [
        "model = Network(ResBlock)\n",
        "model.cuda()\n",
        "\n",
        "# For this homework, we're limiting you to 35 million trainable parameters, as\n",
        "# outputted by this. This is to help constrain your search space and maintain\n",
        "# reasonable training times & expectations\n",
        "num_trainable_parameters = 0\n",
        "for p in model.parameters():\n",
        "    num_trainable_parameters += p.numel()\n",
        "print(\"Number of Params: {}\".format(num_trainable_parameters))\n",
        "\n",
        "# TODO: What criterion do we use for this task?\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
        "# T_max is \"how many times will i call scheduler.step() until it reaches 0 lr?\"\n",
        "\n",
        "# For this homework, we strongly strongly recommend using FP16 to speed up training.\n",
        "# It helps more for larger models.\n",
        "# Go to https://effectivemachinelearning.com/PyTorch/8._Faster_training_with_mixed_precision\n",
        "# and compare \"Single precision training\" section with \"Mixed precision training\" section\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_best_3'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-LS4axUOdlE",
        "outputId": "0bc56afd-d43b-44c7-ab60-ef771ae7b4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzM11HtcboYv"
      },
      "source": [
        "# Let's train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrChwbscbYkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cfa7c1-8a6b-4323-8944-270ca0da7dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70: Train Acc 99.9914%, Train Loss 0.0308, Learning Rate 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.0343%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/70: Train Acc 99.9993%, Train Loss 0.0301, Learning Rate 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/70: Train Acc 99.9878%, Train Loss 0.0290, Learning Rate 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/70: Train Acc 99.9943%, Train Loss 0.0277, Learning Rate 0.0099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.1543%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/70: Train Acc 99.9957%, Train Loss 0.0267, Learning Rate 0.0099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/70: Train Acc 99.9964%, Train Loss 0.0260, Learning Rate 0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/70: Train Acc 99.9993%, Train Loss 0.0249, Learning Rate 0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.1486%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/70: Train Acc 99.9979%, Train Loss 0.0244, Learning Rate 0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/70: Train Acc 99.9957%, Train Loss 0.0243, Learning Rate 0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/70: Train Acc 99.9986%, Train Loss 0.0237, Learning Rate 0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.2286%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/70: Train Acc 99.9986%, Train Loss 0.0232, Learning Rate 0.0094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/70: Train Acc 100.0000%, Train Loss 0.0228, Learning Rate 0.0093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/70: Train Acc 99.9957%, Train Loss 0.0228, Learning Rate 0.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.2857%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/70: Train Acc 99.9979%, Train Loss 0.0222, Learning Rate 0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/70: Train Acc 99.9986%, Train Loss 0.0221, Learning Rate 0.0089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/70: Train Acc 99.9971%, Train Loss 0.0216, Learning Rate 0.0088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.2514%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/70: Train Acc 99.9979%, Train Loss 0.0216, Learning Rate 0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/70: Train Acc 99.9993%, Train Loss 0.0212, Learning Rate 0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/70: Train Acc 99.9986%, Train Loss 0.0208, Learning Rate 0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.4686%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/70: Train Acc 99.9964%, Train Loss 0.0209, Learning Rate 0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/70: Train Acc 99.9993%, Train Loss 0.0207, Learning Rate 0.0079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/70: Train Acc 99.9986%, Train Loss 0.0205, Learning Rate 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.5086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/70: Train Acc 99.9993%, Train Loss 0.0201, Learning Rate 0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/70: Train Acc 100.0000%, Train Loss 0.0200, Learning Rate 0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/70: Train Acc 99.9979%, Train Loss 0.0200, Learning Rate 0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.5543%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/70: Train Acc 100.0000%, Train Loss 0.0197, Learning Rate 0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/70: Train Acc 99.9986%, Train Loss 0.0196, Learning Rate 0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/70: Train Acc 99.9993%, Train Loss 0.0197, Learning Rate 0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.6371%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/70: Train Acc 100.0000%, Train Loss 0.0193, Learning Rate 0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/70: Train Acc 99.9986%, Train Loss 0.0192, Learning Rate 0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/70: Train Acc 100.0000%, Train Loss 0.0191, Learning Rate 0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.6829%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/70: Train Acc 100.0000%, Train Loss 0.0188, Learning Rate 0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/70: Train Acc 100.0000%, Train Loss 0.0189, Learning Rate 0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/70: Train Acc 99.9993%, Train Loss 0.0187, Learning Rate 0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.7914%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/70: Train Acc 100.0000%, Train Loss 0.0184, Learning Rate 0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/70: Train Acc 100.0000%, Train Loss 0.0184, Learning Rate 0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/70: Train Acc 100.0000%, Train Loss 0.0181, Learning Rate 0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.9486%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/70: Train Acc 99.9993%, Train Loss 0.0181, Learning Rate 0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/70: Train Acc 99.9993%, Train Loss 0.0180, Learning Rate 0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/70: Train Acc 100.0000%, Train Loss 0.0180, Learning Rate 0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.8400%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/70: Train Acc 99.9993%, Train Loss 0.0179, Learning Rate 0.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/70: Train Acc 100.0000%, Train Loss 0.0177, Learning Rate 0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/70: Train Acc 100.0000%, Train Loss 0.0176, Learning Rate 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.9514%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/70: Train Acc 100.0000%, Train Loss 0.0175, Learning Rate 0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/70: Train Acc 99.9993%, Train Loss 0.0176, Learning Rate 0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/70: Train Acc 100.0000%, Train Loss 0.0174, Learning Rate 0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.9600%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/70: Train Acc 99.9993%, Train Loss 0.0173, Learning Rate 0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/70: Train Acc 100.0000%, Train Loss 0.0172, Learning Rate 0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/70: Train Acc 99.9993%, Train Loss 0.0172, Learning Rate 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.9943%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/70: Train Acc 100.0000%, Train Loss 0.0170, Learning Rate 0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/70: Train Acc 100.0000%, Train Loss 0.0170, Learning Rate 0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/70: Train Acc 100.0000%, Train Loss 0.0170, Learning Rate 0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/70: Train Acc 100.0000%, Train Loss 0.0169, Learning Rate 0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/70: Train Acc 100.0000%, Train Loss 0.0168, Learning Rate 0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/70: Train Acc 100.0000%, Train Loss 0.0167, Learning Rate 0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/70: Train Acc 100.0000%, Train Loss 0.0168, Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/70: Train Acc 100.0000%, Train Loss 0.0167, Learning Rate 0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/70: Train Acc 100.0000%, Train Loss 0.0167, Learning Rate 0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0343%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/70: Train Acc 100.0000%, Train Loss 0.0166, Learning Rate 0.0006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/70: Train Acc 100.0000%, Train Loss 0.0165, Learning Rate 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/70: Train Acc 100.0000%, Train Loss 0.0164, Learning Rate 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0457%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/70: Train Acc 100.0000%, Train Loss 0.0165, Learning Rate 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/70: Train Acc 99.9993%, Train Loss 0.0165, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/70: Train Acc 100.0000%, Train Loss 0.0165, Learning Rate 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0486%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/70: Train Acc 100.0000%, Train Loss 0.0164, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/70: Train Acc 100.0000%, Train Loss 0.0164, Learning Rate 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/70: Train Acc 100.0000%, Train Loss 0.0163, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0457%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/70: Train Acc 100.0000%, Train Loss 0.0164, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/70: Train Acc 100.0000%, Train Loss 0.0162, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/70: Train Acc 100.0000%, Train Loss 0.0163, Learning Rate 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 85.0629%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    # Quality of life tip: leave=False and position=0 are needed to make tqdm usable in jupyter\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "    num_correct = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    # added after about 80 epochs without this line; re-augmentation for the data; not so sure with this part\n",
        "    train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=ttf.Compose(train_transforms))\n",
        "    # added after about 80 epochs without this line; for previous re-augmentation; not so sure with this part too\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2, pin_memory=False)\n",
        "\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "        # Don't be surprised - we just wrap these two lines to make it work for FP16\n",
        "        with torch.cuda.amp.autocast():    \n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "        # Update # correct & loss as we go\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "        total_loss += float(loss)\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct=num_correct,\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "        \n",
        "        # Another couple things you need for FP16. \n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "    #scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "\n",
        "    if 80 > (100 * num_correct / (len(train_loader) * batch_size)) > 50: # The best accuracy is hard coded here because there were only few changes\n",
        "    # save the model to specified directory\n",
        "      torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_0_tahir')\n",
        "\n",
        "    #if 85 > (100 * num_correct / (len(train_loader) * batch_size)) > 80: # The best accuracy is hard coded here because there were only few changes\n",
        "    # save the model to specified directory\n",
        "      #torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_1_tahir')\n",
        "    #if 90 > (100 * num_correct / (len(train_loader) * batch_size)) > 85: # The best accuracy is hard coded here because there were only few changes\n",
        "    # save the model to specified directory\n",
        "      #torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_2_tahir')\n",
        "    #if 93> (100 * num_correct / (len(train_loader) * batch_size)) > 90: # The best accuracy is hard coded here because there were only few changes\n",
        "    # save the model to specified directory\n",
        "      #torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_3_tahir')\n",
        "    #if (100 * num_correct / (len(train_loader) * batch_size)) > 94: # The best accuracy is hard coded here because there were only few changes\n",
        "    # save the model to specified directory\n",
        "      #torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_4_tahir')\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    # You can add validation per-epoch here if you would like\n",
        "\n",
        "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch + 1,\n",
        "        epochs,\n",
        "        100 * num_correct / (len(train_loader) * batch_size),\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "    if epoch % 3 == 0:\n",
        "      model.eval()\n",
        "      batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "      num_correct = 0\n",
        "      for i, (x, y) in enumerate(val_loader):\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outputs = model(x)\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "        batch_bar.set_postfix(acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)))\n",
        "\n",
        "        batch_bar.update()\n",
        "      \n",
        "      batch_bar.close()\n",
        "      print(\"Validation: {:.04f}%\".format(100 * num_correct / len(val_dataset)))\n",
        "      if 85 > (100 * num_correct / len(val_dataset)) > 84.7:\n",
        "        torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_best_4')\n",
        "      # Final saved model is from here\n",
        "      if (100 * num_correct / len(val_dataset)) > 85:\n",
        "        torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_best_5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model for evaluation\n",
        "model = Network(ResBlock)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_model_hw2p2_best_5'))\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04_fOThgK0jY",
        "outputId": "210e1e3b-2532-4c93-9afe-834c6eb9fb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (3): ResBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (3): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (4): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (5): ResBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): ResBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): ResBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (cls_layer): Linear(in_features=512, out_features=7000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKb2iD_9gdpX"
      },
      "source": [
        "# Classification Task: Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "le1o-OVjfeN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8424fb2-91c3-42e2-dabb-ef6e30f5ffdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: 84.4314%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "num_correct = 0\n",
        "for i, (x, y) in enumerate(val_loader):\n",
        "\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "\n",
        "    num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "    batch_bar.set_postfix(acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)))\n",
        "\n",
        "    batch_bar.update()\n",
        "    \n",
        "batch_bar.close()\n",
        "print(\"Validation: {:.04f}%\".format(100 * num_correct / len(val_dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpgCHImRkYQW"
      },
      "source": [
        "# Classification Task: Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Zv2AWFrfVP"
      },
      "outputs": [],
      "source": [
        "class ClassificationTestSet(Dataset):\n",
        "    # It's possible to load test set data using ImageFolder without making a custom class.\n",
        "    # See if you can think it through!\n",
        "\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # This one-liner basically generates a sorted list of full paths to each image in data_dir\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.transforms(Image.open(self.img_paths[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td_qvGwr16z0"
      },
      "outputs": [],
      "source": [
        "test_dataset = ClassificationTestSet(TEST_DIR, ttf.Compose(val_transforms))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         drop_last=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2WQEUjXkWvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19a321c-ad5a-4499-9965-0c182fc913b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Test')\n",
        "\n",
        "res = []\n",
        "\n",
        "for i, (x) in enumerate(test_loader):\n",
        "\n",
        "    x = x.cuda()\n",
        "    with torch.no_grad():\n",
        "      output = model(x)\n",
        "    outputIndex = torch.argmax(output, axis=1)\n",
        "    for j in outputIndex:\n",
        "      res.append(j)\n",
        "\n",
        "    \n",
        "    # TODO: Finish predicting on the test set.\n",
        "    \n",
        "\n",
        "    batch_bar.update()\n",
        "    \n",
        "batch_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vob9a2-HkW_V"
      },
      "outputs": [],
      "source": [
        "with open(\"classification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(test_dataset)):\n",
        "        f.write(\"{},{}\\n\".format(str(i).zfill(6) + \".jpg\", res[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpxatBfT4jSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee3a5aa-0809-4a5a-9d33-d37ac5579dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 541k/541k [00:03<00:00, 176kB/s]\n",
            "Successfully submitted to Face Recognition"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c 11-785-s22-hw2p2-classification -f classification_early_submission.csv -m yanyuc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsJx1l1T4twC"
      },
      "source": [
        "# Verification Task: Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 6K verification dev images, but 166K \"pairs\" for you to compare. So, it's much more efficient to compute the features for the 6K verification images, and just compare afterwards.\n",
        "\n",
        "This will be done by creating a dictionary mapping the image file names to the features. Then, you'll use this dictionary to compute the similarities for each pair."
      ],
      "metadata": {
        "id": "FoBFFF8-Lpvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls verification/verification/dev | wc -l\n",
        "!cat verification/verification/verification_dev.csv | wc -l"
      ],
      "metadata": {
        "id": "ZV-WsTi9LrVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0a49c7-2eb7-4375-d264-21b1f5b95b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000\n",
            "166801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VerificationDataset(Dataset):\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # This one-liner basically generates a sorted list of full paths to each image in data_dir\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # We return the image, as well as the path to that image (relative path)\n",
        "        return self.transforms(Image.open(self.img_paths[idx])), osp.relpath(self.img_paths[idx], self.data_dir)"
      ],
      "metadata": {
        "id": "m1YtIwxuL7H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98lmjm0S4tHR"
      },
      "outputs": [],
      "source": [
        "val_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/dev\"),\n",
        "                                       ttf.Compose(val_transforms))\n",
        "val_ver_loader = torch.utils.data.DataLoader(val_veri_dataset, batch_size=batch_size, \n",
        "                                             shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(val_ver_loader), total=len(val_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try the final outputs too!\n",
        "        feats = model(imgs, return_feats=True) \n",
        "    \n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow.\n",
        "    for i in range(len(path_names)):\n",
        "      feats_dict[path_names[i]] = feats[i]"
      ],
      "metadata": {
        "id": "-Qw45H-eMyyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f103c02-7f87-407c-fb34-c7d21a750bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What does this dict look like?\n",
        "print(list(feats_dict.items())[0])"
      ],
      "metadata": {
        "id": "k6TG6RD6NTtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f5d633-198a-4593-e652-7483a7195096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('000b28b024.jpg', tensor([ 3.1250e-01,  6.7108e-01, -1.3524e+00, -1.0195e+00,  4.5858e-02,\n",
            "        -2.0668e-01,  8.5356e-01,  4.7467e-01, -2.8756e-01,  3.0829e-01,\n",
            "         9.3832e-01,  1.5700e-01,  2.1148e-01, -5.2564e-01,  6.2312e-01,\n",
            "         2.1136e+00,  6.6637e-01,  1.1524e+00,  1.0871e+00, -4.3531e-01,\n",
            "        -1.4192e+00,  1.0131e-01,  8.4022e-01,  1.2030e+00, -4.2495e-01,\n",
            "        -3.3430e+00, -8.4064e-01,  1.9372e+00,  2.3399e+00, -8.1316e-01,\n",
            "        -3.9912e-01,  2.2055e+00, -1.0767e+00,  6.4047e-01, -2.3388e-01,\n",
            "        -1.5381e-02, -1.9494e+00,  2.0116e+00, -6.4230e-01,  5.0314e-01,\n",
            "         1.2033e+00,  1.5096e+00,  1.3473e-01,  2.5459e-01, -9.1969e-01,\n",
            "        -5.1891e-01, -7.6309e-01, -7.5692e-01, -1.3781e+00, -1.0287e+00,\n",
            "         2.3260e-01, -6.7570e-02,  1.5267e+00, -1.8980e+00, -3.1474e+00,\n",
            "        -9.5311e-01, -7.2163e-01,  2.0189e-01,  2.8438e+00,  1.9456e+00,\n",
            "         1.8539e+00,  9.7716e-01, -1.6888e+00,  3.9599e-01,  1.1082e+00,\n",
            "        -7.1216e-02,  1.4018e+00, -4.9823e-01,  2.3033e+00,  7.5921e-01,\n",
            "        -4.4035e-01,  1.4570e+00, -7.8230e-01, -1.8438e+00, -1.4125e+00,\n",
            "        -8.1051e-01,  1.0703e+00, -1.7345e-01, -7.4445e-01, -8.8493e-01,\n",
            "         8.7914e-01,  6.3453e-01, -1.1585e+00,  1.6861e+00, -3.7193e-01,\n",
            "         5.2480e-01,  8.9733e-01,  3.6698e-02, -5.2735e-01, -3.0053e-01,\n",
            "        -1.4641e+00, -1.3558e+00, -6.4072e-01, -1.6875e+00,  7.1326e-01,\n",
            "        -7.2518e-01, -3.0241e-01, -2.8949e-01, -4.2974e-01, -1.4154e+00,\n",
            "         4.2860e-01, -3.4123e-01, -2.4066e+00, -1.0344e+00,  5.7830e-01,\n",
            "         5.9432e-04,  8.9548e-01, -1.4836e+00, -1.3135e+00, -4.0419e-01,\n",
            "        -2.0444e+00, -2.7335e-01,  9.9840e-01, -5.2933e-01, -1.2743e+00,\n",
            "        -1.0605e+00, -1.7303e+00,  4.7813e-01,  1.2215e+00,  5.3728e-01,\n",
            "         4.9240e-01,  6.9860e-01, -5.8453e-01, -1.1448e+00,  2.0818e+00,\n",
            "         3.3447e-01,  6.7076e-01, -7.0107e-01,  2.0392e+00, -1.6366e-01,\n",
            "        -4.2227e-01, -1.3321e+00,  1.4335e-01, -6.2002e-01, -2.0051e-01,\n",
            "         1.4703e-01, -2.0369e+00, -7.6132e-01,  2.1632e+00,  7.9009e-01,\n",
            "        -2.4598e-02,  6.6412e-01, -5.9511e-01, -2.1302e+00,  1.5230e+00,\n",
            "         1.6569e+00, -1.4496e+00, -1.0592e+00,  2.0601e+00, -4.3924e-01,\n",
            "        -3.2584e-01,  1.7997e+00,  3.1642e-01, -9.8785e-01,  1.4406e+00,\n",
            "         1.4994e+00,  1.6234e+00,  1.3059e+00,  4.6274e-01,  1.4031e+00,\n",
            "        -1.3507e+00,  8.2378e-01, -3.2624e-01,  1.6059e-01, -1.0712e+00,\n",
            "        -7.6488e-01,  1.1331e+00, -7.7439e-01,  5.6268e-01, -9.4409e-02,\n",
            "         3.9630e-01, -1.4806e+00, -1.3291e-01,  4.9555e-01, -1.1391e+00,\n",
            "        -5.9174e-02, -2.1435e+00,  5.3841e-01,  2.7037e-02, -1.9083e+00,\n",
            "        -3.3506e-01,  1.8159e+00,  7.3110e-01,  8.1833e-01,  8.1390e-01,\n",
            "         2.2087e-01,  1.0139e+00,  1.0175e+00, -1.5385e+00,  1.0754e+00,\n",
            "        -1.2079e+00, -1.1213e+00,  5.5766e-02, -3.7569e-01, -1.2500e+00,\n",
            "         3.3407e+00, -8.7677e-01, -1.2384e+00,  3.0712e-01,  1.4775e-01,\n",
            "         2.4061e+00, -2.6711e-01, -1.5456e+00,  8.3783e-01, -4.6474e-01,\n",
            "         1.3037e-01,  1.1076e+00,  1.1383e+00, -1.4273e-01,  3.6041e-01,\n",
            "         1.3865e+00, -2.0801e-01,  1.5766e+00, -5.0643e-01,  5.7312e-02,\n",
            "         8.2899e-01, -7.7742e-01, -1.3029e+00, -9.8925e-01, -8.6233e-01,\n",
            "         1.5515e+00, -1.5474e+00, -1.7140e+00,  1.2606e+00, -2.4154e+00,\n",
            "        -2.3817e+00, -5.2060e-01,  5.3890e-01,  4.0364e-01,  6.3344e-01,\n",
            "        -1.6785e+00, -6.6174e-02, -2.1839e+00, -3.5563e+00, -5.8397e-01,\n",
            "        -6.0036e-01,  2.8215e+00,  2.0267e+00,  6.8207e-01, -5.4220e-01,\n",
            "         2.0604e+00,  1.6912e+00,  5.9620e-01, -1.5546e+00, -7.9429e-01,\n",
            "        -1.8110e-01, -2.8723e-01,  1.9209e-01, -6.8832e-01, -9.1315e-01,\n",
            "         2.1204e+00,  1.4817e-01,  1.0288e-02, -1.2576e+00,  1.6827e-01,\n",
            "        -3.8486e-01, -2.7538e-01,  1.7291e-01, -1.8327e+00, -2.2271e-01,\n",
            "         9.9045e-01, -4.1023e-01,  3.3650e-01, -8.8435e-01, -2.3042e+00,\n",
            "        -1.0865e-02,  2.5608e+00, -1.3794e+00, -1.2537e+00,  1.4546e+00,\n",
            "         3.0218e-01,  1.0406e+00,  2.5406e-01,  7.2585e-01,  1.5895e+00,\n",
            "         6.5354e-01,  1.7475e+00, -5.1920e-01, -2.1029e+00, -5.0627e-01,\n",
            "        -5.2193e-01, -7.2425e-01, -9.5088e-01, -7.0684e-01, -1.8938e+00,\n",
            "        -4.2997e-01, -7.9589e-02,  1.6750e+00, -1.4193e-01,  3.9376e-01,\n",
            "         2.5680e-01,  1.8143e-01, -1.3211e+00, -1.6474e+00,  3.9471e-01,\n",
            "         7.6947e-01, -3.9942e-01,  1.0718e+00,  1.4614e+00,  1.0081e+00,\n",
            "         1.7196e-01,  2.5556e-01, -1.3267e+00, -8.9891e-01, -8.7303e-01,\n",
            "        -2.9082e+00,  2.5955e-01, -5.3019e-01,  6.4429e-01,  2.9845e+00,\n",
            "         3.6407e-01,  1.8617e-01, -1.8492e+00, -1.9323e-01,  3.4809e-01,\n",
            "         2.2820e+00, -4.0412e-01,  2.4617e+00,  9.0634e-01,  6.6546e-01,\n",
            "        -6.3531e-03,  1.8331e+00, -1.6028e+00, -1.2210e+00,  1.4775e+00,\n",
            "         1.2479e+00,  1.9654e+00, -1.5139e-01, -3.7179e-01, -1.1839e+00,\n",
            "        -4.7758e-02,  8.2646e-01,  3.3275e-01, -8.2487e-01,  2.8035e-01,\n",
            "        -6.5949e-01,  9.6022e-01, -1.1985e+00,  7.7808e-01, -1.7966e+00,\n",
            "         1.4887e+00, -5.0509e-01, -2.7171e-01, -1.8467e+00,  1.1449e+00,\n",
            "        -1.6697e+00,  1.7177e+00,  6.9681e-01, -1.3605e+00,  9.2378e-01,\n",
            "         3.3683e-01,  1.8344e-01, -5.3261e-01,  1.2519e+00,  6.9477e-01,\n",
            "        -5.6392e-01, -6.5046e-01,  6.7016e-01, -5.6874e-01,  3.3910e-01,\n",
            "        -6.4807e-01, -3.3136e-01,  3.1398e-01, -1.1608e+00, -3.9398e-01,\n",
            "         2.3024e-01,  5.4044e-01,  2.3602e+00,  7.5731e-01,  3.0889e-01,\n",
            "         1.2453e+00,  5.3096e-01,  2.6084e-01,  1.2273e-01, -1.6295e+00,\n",
            "        -1.5894e+00,  1.9809e+00, -2.9468e-01, -2.1164e+00,  3.8880e-01,\n",
            "         1.5042e+00,  9.6624e-01,  4.3776e-01,  1.3388e-01, -4.4148e-01,\n",
            "         3.6428e-01, -1.3414e+00, -4.2969e-01,  2.2506e-01,  2.0572e-01,\n",
            "         2.2380e-01,  2.4790e+00,  3.3953e-02, -1.4027e+00,  5.1273e-01,\n",
            "        -1.1269e+00, -2.0494e-01,  4.4145e-01,  6.9083e-01,  2.2783e-01,\n",
            "        -1.6805e+00,  4.8148e-01, -6.3546e-01, -5.2955e-01, -8.0106e-01,\n",
            "         9.3032e-01,  1.5793e+00, -1.6151e+00, -4.3081e-01, -2.2436e+00,\n",
            "         1.1487e+00,  1.7153e+00, -4.0246e-01, -3.0837e-01, -5.7649e-01,\n",
            "         8.0089e-01,  9.8094e-01,  1.0198e+00, -1.7785e+00, -7.6002e-01,\n",
            "        -3.0852e-02,  3.7981e-01,  4.9186e-03,  5.4402e-01,  4.9853e-01,\n",
            "         1.0030e+00,  1.1861e+00,  1.2883e+00,  1.0286e+00,  1.7242e+00,\n",
            "         7.0226e-01,  1.1984e+00, -8.9539e-02, -5.1155e-01, -2.5142e-01,\n",
            "        -1.3794e-01, -7.6930e-01, -1.8004e-01, -1.0894e+00,  3.8480e-01,\n",
            "         4.7589e-01,  4.6017e-01,  5.9108e-01, -9.1635e-01, -1.2401e+00,\n",
            "         4.7111e-01, -1.6020e+00,  1.9458e-01, -6.4847e-01,  1.0329e+00,\n",
            "         1.4490e+00,  7.3241e-01, -1.5552e-02, -1.1687e+00,  2.0430e-03,\n",
            "        -6.9084e-01, -1.5838e+00, -1.0113e+00,  5.4202e-02, -9.9642e-01,\n",
            "        -4.8440e-01, -1.1702e-01,  1.3730e+00,  6.7266e-01,  8.1486e-01,\n",
            "        -6.6029e-01,  1.5097e+00,  9.9359e-01, -3.7018e-01, -6.7987e-01,\n",
            "        -7.3685e-02, -7.3822e-01, -1.7232e-01, -3.5860e-01,  7.5172e-01,\n",
            "        -2.1672e+00, -3.6049e-01,  4.9133e-01, -4.6640e-01, -4.7889e-01,\n",
            "         5.7309e-01,  9.6055e-01,  2.0908e-01,  4.8255e-01, -8.2023e-01,\n",
            "        -1.9221e+00,  2.0400e+00, -6.4391e-01, -1.7755e+00,  3.1601e-01,\n",
            "         6.4305e-01, -5.4408e-01,  5.1097e-01, -1.1533e-01, -8.8706e-01,\n",
            "        -1.6056e+00,  2.0649e+00,  8.7044e-01,  8.2933e-01, -1.3461e+00,\n",
            "         2.9922e+00, -2.0204e-02,  1.9484e+00,  1.8114e+00, -8.4789e-02,\n",
            "         1.5529e+00,  8.2837e-01, -2.7438e-01, -1.9319e-01,  9.6032e-02,\n",
            "        -2.0096e+00,  1.5729e+00], device='cuda:0'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "similarity_metric = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "\n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_dev.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "gt_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2, gt = line.split(\",\")\n",
        "\n",
        "    # TODO: Use the similarity metric\n",
        "    # How to use these img_paths? What to do with the features?\n",
        "    # similarity = similarity_metric(...)\n",
        "\n",
        "    feats1 = feats_dict.get(img_path1[4:])\n",
        "    feats2 = feats_dict.get(img_path2[4:])\n",
        "    similarity = similarity_metric(feats1, feats2)\n",
        "    similarity = similarity.to(torch.device('cpu'))\n",
        "    pred_similarities.append(similarity)\n",
        "\n",
        "    gt_similarities.append(int(gt))\n",
        "\n",
        "pred_similarities = np.array(pred_similarities)\n",
        "gt_similarities = np.array(gt_similarities)\n",
        "\n",
        "print(\"AUC:\", roc_auc_score(gt_similarities, pred_similarities))"
      ],
      "metadata": {
        "id": "_zuqds2qNO6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5f2dc5-8bb8-4641-8e82-44d3acfe4808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9586054596376377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verification Task: Submit to Kaggle"
      ],
      "metadata": {
        "id": "sakRa8oZOlKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/test\"),\n",
        "                                        ttf.Compose(val_transforms))\n",
        "test_ver_loader = torch.utils.data.DataLoader(test_veri_dataset, batch_size=batch_size, \n",
        "                                              shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "oDK3knDcOrOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(test_ver_loader), total=len(test_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try to final outputs too!\n",
        "        feats = model(imgs, return_feats=True) \n",
        "    \n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow.\n",
        "    for i in range(len(path_names)):\n",
        "      feats_dict[path_names[i]] = feats[i]"
      ],
      "metadata": {
        "id": "igeRT3WxOrB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d2dc81-f3a8-46dc-fa5d-8a0574bf7cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "# similarity_metric = \n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_test.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2 = line.split(\",\")\n",
        "\n",
        "    # TODO: Finish up verification testing.\n",
        "    # How to use these img_paths? What to do with the features?\n",
        "    feats1 = feats_dict.get(img_path1[5:])\n",
        "    feats2 = feats_dict.get(img_path2[5:])\n",
        "    similarity = similarity_metric(feats1, feats2)\n",
        "    similarity = similarity.to(torch.device('cpu'))\n",
        "    pred_similarities.append(similarity)"
      ],
      "metadata": {
        "id": "X4OZL_FNOq1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f859b3-4fff-4fc7-9c05-7fbc69c8e4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"verification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,match\\n\")\n",
        "    for i in range(len(pred_similarities)):\n",
        "        f.write(\"{},{}\\n\".format(i, pred_similarities[i]))"
      ],
      "metadata": {
        "id": "fYXiglWkPBDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5zB7P8O687N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61246cce-f9bb-4007-fa95-d747d3933bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 16.9M/16.9M [00:03<00:00, 4.97MB/s]\n",
            "Successfully submitted to Face Verification"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c 11-785-s22-hw2p2-verification -f verification_early_submission.csv -m yanyuc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALiq9PTl7KwY"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuAsK_tKhzH9"
      },
      "outputs": [],
      "source": [
        "# If you keep re-initializing your model in Colab, can run out of GPU memory, need to restart.\n",
        "# These three lines can help that - run this before you re-initialize your model\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HW2P2_Starter.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}